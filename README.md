# Implementation of the Transformer Architecture
[![Open Transfomer in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YooPaul/Transformer/blob/master/Transformer.ipynb)<br>

Easily customizable implementation of the Transformer architecture.<br>
Components include multi-headed self-attention and cross-attention, layer normalization, positional encoding, stacked encoder and decoder architectures.


## References

[1] Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. "Attention is all you need." In Advances in neural information processing systems, pp. 5998-6008. 2017.

[2] https://jalammar.github.io/illustrated-transformer/ 

