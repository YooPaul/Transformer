{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "ELBosJ2dI1Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "!ls /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqW9xBbn5m9Z",
        "outputId": "4db1408a-69cd-4faa-9c81-9dea16701ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n",
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2O47WqtL8aF",
        "outputId": "0213dce8-3278-43f8-e217-2390bb1d3d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "dHTG80VyJJyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English-Japanese Translation Dataset\n",
        "!wget https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz\n",
        "!tar -xf raw.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5CtCBpxMspu",
        "outputId": "fad69e77-3167-457e-f87b-fa2e6fb77822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-25 06:10:32--  https://nlp.stanford.edu/projects/jesc/data/raw.tar.gz\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102198198 (97M) [application/x-gzip]\n",
            "Saving to: ‘raw.tar.gz’\n",
            "\n",
            "raw.tar.gz          100%[===================>]  97.46M  22.3MB/s    in 5.5s    \n",
            "\n",
            "2021-12-25 06:10:38 (17.8 MB/s) - ‘raw.tar.gz’ saved [102198198/102198198]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head raw/raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySBJVGnFMrII",
        "outputId": "92b3e514-2c0a-4a70-9d59-7cb55b4f3ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are back, aren't you, harold?\tあなたは戻ったのね ハロルド?\n",
            "my opponent is shark.\t俺の相手は シャークだ。\n",
            "this is one thing in exchange for another.\t引き換えだ ある事とある物の\n",
            "yeah, i'm fine.\tもういいよ ごちそうさま ううん\n",
            "don't come to the office anymore. don't call me either.\tもう会社には来ないでくれ 電話もするな\n",
            "looks beautiful.\tきれいだ。\n",
            "get him out of here, because i will fucking kill him.\t連れて行け 殺しそうだ わかったか?\n",
            "you killed him!\t殺したのか!\n",
            "okay, then who?\tわぁ~! いつも すみません。 いいのよ~。\n",
            "it seems a former employee...\tカンパニーの元社員が\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ],
      "metadata": {
        "id": "1niQR3eKRsTl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOgcJNLGQocG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from math import sin, cos, sqrt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation"
      ],
      "metadata": {
        "id": "ccNEqxLWU8qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dictionary to map tokens to indices\n",
        "import string\n",
        "data = 'raw/raw' # path to the data file\n",
        "dataset = []\n",
        "enc_dic = {}\n",
        "dec_dic = {}\n",
        "dec_dic['<sos>'] = len(dec_dic)\n",
        "dec_dic['<eos>'] = len(dec_dic)\n",
        "enc_dic['<pad>'] = len(enc_dic)\n",
        "dec_dic['<pad>'] = len(dec_dic)\n",
        "\n",
        "max_seq1_len = 31\n",
        "max_seq2_len = 30\n",
        "\n",
        "with open(data) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        s1, s2 = line[:-1].split('\\t')\n",
        "        enc_seq = []\n",
        "        dec_seq = []\n",
        "        for token in s1.split(' '):\n",
        "            tokens_to_add = []\n",
        "            if token[-1] in string.punctuation:\n",
        "                tokens_to_add.append(token[:-1])\n",
        "                tokens_to_add.append(token[-1])\n",
        "            else:\n",
        "                tokens_to_add.append(token)\n",
        "            \n",
        "            for t in tokens_to_add:\n",
        "                if t not in enc_dic:\n",
        "                    enc_dic[t] = len(enc_dic)\n",
        "            enc_seq = enc_seq + tokens_to_add\n",
        "        \n",
        "        for char in s2:\n",
        "            \n",
        "            if char not in dec_dic:\n",
        "                    dec_dic[char] = len(dec_dic)\n",
        "            dec_seq.append(char)\n",
        "        \n",
        "        if len(enc_seq) <= max_seq1_len and len(dec_seq) <= max_seq2_len:\n",
        "            dataset.append((enc_seq, dec_seq))"
      ],
      "metadata": {
        "id": "5M5h_0hIU-ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dataset\n",
        "class EngJpDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, transforms=None):\n",
        "        super(EngJpDataset, self).__init__()\n",
        "        self.data = data\n",
        "        self.transforms = transforms\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        seq1, seq2 = self.data[idx]\n",
        "        enc_input = [enc_dic[token] for token in seq1]\n",
        "\n",
        "        # For decoder inputs, add <sos> and <eos> tokens\n",
        "        dec_input = [dec_dic['<sos>']] + [dec_dic[token] for token in seq2] + [dec_dic['<eos>']]\n",
        "        \n",
        "        # Pad both encoder and decoder inputs\n",
        "        for i in range(len(enc_input), max_seq1_len):\n",
        "            enc_input.append(enc_dic['<pad>'])\n",
        "\n",
        "        for i in range(len(dec_input), max_seq2_len + 2):\n",
        "            dec_input.append(dec_dic['<pad>'])\n",
        "        \n",
        "        # Convert to tensors\n",
        "        seq1 = torch.tensor(enc_input)\n",
        "        seq2 = torch.tensor(dec_input)\n",
        "        return seq1, seq2"
      ],
      "metadata": {
        "id": "ZgXjNg9j_l8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Modules"
      ],
      "metadata": {
        "id": "1NLNUl6_SXru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A lookup table mapping integer index to an embedding\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, num_unique_tokens, embed_dim):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embed = nn.Embedding(num_unique_tokens, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x -> N x Seq \n",
        "        x = self.embed(x)\n",
        "        # x -> N x Seq x embed_dim\n",
        "        return x"
      ],
      "metadata": {
        "id": "mV3JTh6GL4vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A method for encoding positional information using sin and cos waves\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_sequence_len, embed_dim, device):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        self.position_matrix = torch.zeros((max_sequence_len, embed_dim), device=device, requires_grad=False)\n",
        "        for pos in range(max_sequence_len):\n",
        "            for i in range(0, embed_dim, 2):\n",
        "                self.position_matrix[pos][i] = sin(pos / 10000**(2*i/embed_dim))\n",
        "                self.position_matrix[pos][i + 1] = cos(pos / 10000**(2*(i + 1)/embed_dim))\n",
        "\n",
        "        self.position_matrix = self.position_matrix.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        sequence_len = x.shape[1]\n",
        "        x = x + self.position_matrix[:,:sequence_len]\n",
        "        return x"
      ],
      "metadata": {
        "id": "ixyQG0MMLzsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization module\n",
        "class Normalization(nn.Module):\n",
        "    def __init__(self, embed_dim, method='L'):\n",
        "        super(Normalization, self).__init__()\n",
        "        self.method = method\n",
        "\n",
        "        if self.method not in ['L', 'B']:\n",
        "            self.method = 'L'\n",
        "        self.gamma = nn.Parameter(torch.ones(embed_dim))\n",
        "        self.beta = nn.Parameter(torch.zeros(embed_dim))\n",
        "        self.eps = 1e-7\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x -> N x seq x embed_dim\n",
        "\n",
        "        # Batch Norm\n",
        "        if self.method == 'B':\n",
        "            pass\n",
        "        # Layer Norm \n",
        "        elif self.method == 'L':\n",
        "            mu = torch.mean(x, dim=-1, keepdim=True)\n",
        "            var = torch.var(x, dim=-1, keepdim=True)\n",
        "            x = (x - mu) / torch.sqrt(var + self.eps)\n",
        "            x = self.gamma * x + self.beta\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Rhivy3DDn-B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention mechanism\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, embed_dim, latent_dim, device):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.W_Q = nn.Linear(embed_dim, latent_dim, device=device)\n",
        "        self.W_K = nn.Linear(embed_dim, latent_dim, device=device)\n",
        "        self.W_V = nn.Linear(embed_dim, latent_dim, device=device)\n",
        "\n",
        "        self.scale = sqrt(latent_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        Q = self.W_Q(x)\n",
        "        K = self.W_K(x)\n",
        "        V = self.W_V(x)\n",
        "\n",
        "        scores = torch.matmul(Q, torch.transpose(K,1,2)) / self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -float('inf'))\n",
        "\n",
        "        scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "        return torch.matmul(scores, V)\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, latent_dim, device, num_heads):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "\n",
        "        if num_heads < 1:\n",
        "            num_heads = 1\n",
        "\n",
        "        self.attention_heads = nn.ModuleList([Attention(embed_dim, latent_dim, device) for _ in range(num_heads)])\n",
        "        self.W = nn.Linear(latent_dim * num_heads, embed_dim) # bring back to the original input dimensions\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        heads = []\n",
        "        for i, head in enumerate(self.attention_heads):\n",
        "            heads.append(head(x, mask))\n",
        "        z = torch.concat(heads, dim=-1)\n",
        "        return self.W(z)\n"
      ],
      "metadata": {
        "id": "1hWc7CKPwpdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Encoder\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HT_reYLE26k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embed_dim, latent_dim, device, num_heads, dropout=0.2):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.multi_head_attention = MultiHeadedAttention(embed_dim, latent_dim, device, num_heads)\n",
        "        self.normalize1 = Normalization(embed_dim)\n",
        "        self.normalize2 = Normalization(embed_dim)\n",
        "\n",
        "        self.dp1 = nn.Dropout(dropout)\n",
        "        self.dp2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.feed_forward = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # x -> Batch_size x Seq_len x embed_dim\n",
        "        \n",
        "        x = x + self.dp1(self.multi_head_attention(x, mask))\n",
        "        x = self.normalize1(x)\n",
        "        x = x + self.dp2(F.relu(self.feed_forward(x)))\n",
        "        x = self.normalize2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HxSTWOkr3JlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, num_unique_tokens, max_sequence_len, embed_dim, latent_dim, device, num_heads, num_encoders, dropout=0.2):\n",
        "        super(EncoderStack, self).__init__()\n",
        "\n",
        "        self.embedding = Embedding(num_unique_tokens, embed_dim)\n",
        "        self.pos_encoding = PositionalEncoding(max_sequence_len, embed_dim, device)\n",
        "        self.encoders = nn.ModuleList([Encoder(embed_dim, latent_dim, device, num_heads, dropout) for _ in range(num_encoders)])\n",
        "\n",
        "        self.W_K = nn.Linear(embed_dim, embed_dim)\n",
        "        self.W_V = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoding(x)\n",
        "        for i, encoder in enumerate(self.encoders):\n",
        "            x = encoder(x, mask)\n",
        "        K = self.W_K(x)\n",
        "        V = self.W_V(x)\n",
        "        return K, V"
      ],
      "metadata": {
        "id": "sGrwn_OPNtAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> ### Decoder\n",
        "\n"
      ],
      "metadata": {
        "id": "JKxBRChk3Mii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embed_dim, latent_dim, device, num_heads, dropout=0.2):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.multi_head_attention = MultiHeadedAttention(embed_dim, latent_dim, device, num_heads)\n",
        "        self.normalize1 = Normalization(embed_dim)\n",
        "        self.normalize2 = Normalization(embed_dim)\n",
        "        self.normalize3 = Normalization(embed_dim)\n",
        "\n",
        "        self.dp1 = nn.Dropout(dropout)\n",
        "        self.dp2 = nn.Dropout(dropout)\n",
        "        self.dp3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.W_Q = nn.Linear(embed_dim, embed_dim)\n",
        "        self.feed_forward = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x, K, V, enc_mask=None, dec_mask=None):\n",
        "        # x -> Batch_size x Seq_len x embed_dim\n",
        "        \n",
        "        # Self-attention uses decoder mask\n",
        "        x = x + self.dp1(self.multi_head_attention(x, dec_mask))\n",
        "        x = self.normalize1(x)\n",
        "\n",
        "        # Cross-attention\n",
        "        Q = self.W_Q(x)\n",
        "        scores = torch.matmul(Q, torch.transpose(K,1,2)) / sqrt(x.shape[-1])\n",
        "\n",
        "        # Use encoder mask\n",
        "        if enc_mask is not None:\n",
        "            scores = scores.masked_fill(enc_mask == 0, -float('inf'))\n",
        "\n",
        "        scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "        x = x + self.dp2(torch.matmul(scores, V))\n",
        "        x = self.normalize2(x)\n",
        "\n",
        "        x = x + self.dp3(F.relu(self.feed_forward(x)))\n",
        "        x = self.normalize3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qeOxniMh67HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, num_unique_tokens, max_sequence_len, embed_dim, latent_dim, device, num_heads, num_decoders, dropout=0.2):\n",
        "        super(DecoderStack, self).__init__()\n",
        "\n",
        "        self.embedding = Embedding(num_unique_tokens, embed_dim)\n",
        "        self.pos_encoding = PositionalEncoding(max_sequence_len, embed_dim, device)\n",
        "        self.decoders = nn.ModuleList([Decoder(embed_dim, latent_dim, device, num_heads, dropout) for _ in range(num_decoders)])\n",
        "\n",
        "        self.linear = nn.Linear(embed_dim, num_unique_tokens)\n",
        "\n",
        "    def forward(self, x, K, V, enc_mask=None, dec_mask=None):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoding(x)\n",
        "        for i, decoder in enumerate(self.decoders):\n",
        "            x = decoder(x, K, V, enc_mask, dec_mask)\n",
        "        return self.linear(x) # softmax activation applied by the cross entropy loss function"
      ],
      "metadata": {
        "id": "jS68RWdLNocI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Transformer Module\n",
        "\n"
      ],
      "metadata": {
        "id": "7nHS3vqgMoX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_unique_input_tokens, num_unique_output_tokens, max_sequence_len, embed_dim, latent_dim, device, num_heads, num_stacks, dropout=0.2):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_stack = EncoderStack(num_unique_input_tokens, max_sequence_len, embed_dim, latent_dim, device, num_heads, num_stacks, dropout)\n",
        "        self.decoder_stack = DecoderStack(num_unique_output_tokens, max_sequence_len, embed_dim, latent_dim, device, num_heads, num_stacks, dropout)\n",
        "        \n",
        "\n",
        "    def forward(self, enc_seq, dec_seq, enc_mask, dec_mask):\n",
        "        K, V = self.encoder_stack(enc_seq, enc_mask)\n",
        "        out = self.decoder_stack(dec_seq, K, V, enc_mask, dec_mask)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7mX-8ZSz7DZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "ipIKy4ADRrNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 25\n",
        "\n",
        "full_dataset = EngJpDataset(dataset)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "\n",
        "model = Transformer(len(enc_dic), len(dec_dic), 80, 512, 64, device, 8, 6, dropout=0.1)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "#t = transforms.Compose([transforms.ToPILImage(mode='F'), transforms.Resize(32), transforms.ToTensor()])\n",
        "#t = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "#num_workers = multiprocessing.cpu_count()\n",
        "#print('num workers:', num_workers)\n",
        "\n",
        "kwargs = {'num_workers': 1, #num_workers,\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                                            shuffle=True, **kwargs)\n",
        "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                                            shuffle=True, **kwargs)\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for idx, (enc_input, dec_input) in enumerate(train):\n",
        "    optim.zero_grad()\n",
        "    \n",
        "    # enc_input, dec_input -> N x Seq\n",
        "    enc_input, dec_input = enc_input.to(device), dec_input.to(device)\n",
        "\n",
        "    enc_mask = (enc_input != enc_dic['<pad>']).unsqueeze(1)\n",
        "    dec_mask = (dec_input[:, :-1] != dec_dic['<pad>']).unsqueeze(1) & (torch.triu(torch.ones((max_seq2_len + 1, max_seq2_len + 1)), diagonal=1)==0).to(device)\n",
        "\n",
        "    output = model(enc_input, dec_input[:, :-1], enc_mask, dec_mask)\n",
        "    \n",
        "    # Remove all the <pad> tokens as we don't want to penalize the model for not learning the paddings\n",
        "    ground_truth = dec_input[:,1:].reshape(-1)\n",
        "    output = output.view(-1, output.shape[-1]) # output -> (N * Seq) x Vocab_size \n",
        "    \n",
        "    loss = F.cross_entropy(output[ground_truth != dec_dic['<pad>']], ground_truth[ground_truth != dec_dic['<pad>']])\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if idx % 10 == 0:\n",
        "      print('Epoch:', epoch)\n",
        "      print('Loss:', loss.item())\n",
        "      #torch.save(model, '/content/drive/MyDrive/Colab Notebooks/models/' + 'transformer.pt')\n",
        "\n",
        "print('Finished training model')"
      ],
      "metadata": {
        "id": "tKSoDaQ9Rupn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "VdCMfa9Ix5gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "idx_to_token = {}\n",
        "\n",
        "for key, value in dec_dic.items():\n",
        "    idx_to_token[value] = key\n",
        "\n",
        "enc_input = 'hi nice to meet you'.split(' ')\n",
        "enc_input = torch.tensor([enc_dic[token] for token in enc_input]).unsqueeze(0).to(device)\n",
        "\n",
        "dec_input = torch.tensor([dec_dic['<sos>']]).unsqueeze(0).to(device)\n",
        "\n",
        "i = 0\n",
        "while True:\n",
        "    output = model(enc_input, dec_input, None, None)\n",
        "\n",
        "    idx = torch.argmax(output[0][-1], dim=-1).item()\n",
        "    token = idx_to_token[idx]\n",
        "    print(token)\n",
        "\n",
        "    i += 1\n",
        "    if i > 30 or token == '<eos>':\n",
        "        break\n",
        "    dec_input = torch.cat((dec_input, torch.tensor([[idx]]).to(device)), dim=-1)\n"
      ],
      "metadata": {
        "id": "HHiSudLoXPgX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}